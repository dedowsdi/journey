black screen debug:
    1. make sure no error message in debug output.
    2. make sure draw call happens, could be glCallList, glDraw*
    3. make sure drawable is not clipped, you may use apitrace or othertool to
       get mvpw_mat, test it with a point that you 100% sure shoulde be visible.
    4. make sure vertex data is right, check the location, size, stride, offset.
    5. make sure it pass depth test if it's enabled, make sure depth buffer is
       cleared, also check current depth func.
    6. make sure it's not clipped alway by clip planes.
    7. make sure it pass stentil test if it's enabled.

-----------
2018.01.13:

lighting of normalmap is prefered to be calculated in tangent space(so there has
no transform in fs shader), which means you have to transform light, camera into
tangent space in vertex shader. Local viewer must always be true(it can be
false only in view space)

Although it's easier to calculate normalmap lighting in view space, you only
need to transfrom normal from tbn space to view space in fragment shader, as
long as performance is not an issue.

-----------
2018.01.16:

freeimage:
  FreeImage uses a BGR[A] pixel layout under a Little Endian processor (Windows, Linux) and uses a
  RGB[A] pixel layout under a Big Endian  processor (Mac OS X or any Big Endian Linux / Unix). 

-----------
2018.01.18:

it's totally legal to bind the same buffer to different target.

-----------
2018.01.30:

normal achieved from normal eexture still needs to be normalized:
// be very careful about this!!, not easay to debug, totally nightmare
vec3 t_normal = normalize(texture(normal_map, fi.texcoord).xyz * 2 - 1); 

-----------
2018.02.03:

gl:
  if you change marcro that will change uniform size(such as light_count), you
  need to rebind all uniform locations.

-----------
2018.02.12:

gl:
  After a serious of yaw and pitch, your camera will be tilted.  You need to get
  current eye position and use look at to fix up.

----------
2018.10.04

glsl:
  pow(x,y) only works for positive x

----------
2018.10.15

freeimage:
  some image use 8 bpp, but it might be color index.
  I should always convert image to 32bits before i use it in opengl.

-----------
2018.11.2

gl:
  The contents of the back buffer become undefined after a swap.

-----------
2018.11.5

opengl:
  a buffer texture is simply a way for the shader to directly access a large
  array of data, generally larger than uniform buffer objects allow.

-----------
2018.11.8

gl:
  you must use multisample texture if you want to enable multisample during rtt:
     glBindTexture(GL_TEXTURE_2D_MULTISAMPLE, tex);
     glTexImage2DMultisample(GL_TEXTURE_2D_MULTISAMPLE, samples, GL_RGBA8, width, height, false);
     glBindFramebuffer(GL_FRAMEBUFFER, fbo);
     glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0,
     GL_TEXTURE_2D_MULTISAMPLE, tex, 0)

  you can sample multisample texture like this:
    uniform int texSamples;
    uniform sampler2DMS tex;

    vec4 textureMultisample(sampler2DMS sampler, ivec2 coord)
    {
        vec4 color = vec4(0.0);

        for (int i = 0; i < texSamples; i++)
            color += texelFetch(sampler, coord, i);

        color /= float(texSamples);

        return color;
    }

  it's quite bulky, you might want to use default framebuffer and
  glCopyTexImage2D instead.

-----------
2018.11.12
DMA: direct memory access

by default, gl_FragCoord starts at (0.5, 0.5),  this can be changed by layout
qualifier.

Assume you have two point A, B in clip space, and another point C between them as:
    C = A * (1 - t) + B * t ( xy part)
    If you wan to get perspective correct vertex attribute for C, you must know that:
        1/C_w = (1 - t) / A_w  + t / B_w
        X_w is negative camera space z here.
    With that in mind, you can get perspective correct vertex attribute for C as:
        C_w * (A_x * (1-t) / A_w + B_x * t / B_w)
    check https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/perspective-correct-interpolation-vertex-attributes for detail

    The same rule applies for point D inside triangle ABC, you just have to replace t with barycentric coordinates:
        D_w * (A_x * λ0 / A_w + B_x * λ1 / B_w * C_x * λ2 / C_w)


be very very careful when you add 2 vertices as vec4, it's w component will be added together, most of time it's not what you want!!!!!!.

never use the same texture for both input and output, that's a UB, a nightmare.

-------------------
Font rendering:

font size
Font height is often measured in pt(points), 72.272 points = 1inch = 2.54 cm

For digital screen, dpi is the same as ppi.

em square
An imaginary square that is used to size and align glyphs, the glyph might extent beyond the square .

FUnit
true type font point locations are described in font unit, it's in [-16384, 16383]

upem
units per em square side.

em square

dpi
Device resolution, dot per inch

ppi
Device resolution, pixel per inch

converting FUnits to pixels:
If a glyph feature is 550 FUnits in length, it's upem is 2048, your screen use
dpi=72, pointSize is 18:

The whole em square length is 72 * 18 / 72 = 18 pixels.
This glyph feature length is 550.0 / 2048 * 18 = 4.83
pixel size = dpi * (pointSize/72) * (glyph funits length)/upem
ppem = dpi * pointSize / 72

pixel_coordinate = em_coordinate * ppem /upem
